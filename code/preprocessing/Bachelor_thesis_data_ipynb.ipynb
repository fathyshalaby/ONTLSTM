{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Bachelor thesis data ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwuC1H5GiACE",
        "colab_type": "text"
      },
      "source": [
        "# **Importing and setting up the enviroments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpdkAxsUkFco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "3a9a7471-4844-41e3-cda7-509052e8f45f"
      },
      "source": [
        "import pickle\n",
        "import h5py\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import Bio\n",
        "import widis_lstm_tools\n",
        "import torch\n",
        "import ipywidgets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.78\n",
            "Collecting git+https://github.com/widmi/widis-lstm-tools\n",
            "  Cloning https://github.com/widmi/widis-lstm-tools to /tmp/pip-req-build-mrmj9oea\n",
            "  Running command git clone -q https://github.com/widmi/widis-lstm-tools /tmp/pip-req-build-mrmj9oea\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from widis-lstm-tools==0.4) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from widis-lstm-tools==0.4) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from widis-lstm-tools==0.4) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->widis-lstm-tools==0.4) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->widis-lstm-tools==0.4) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->widis-lstm-tools==0.4) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->widis-lstm-tools==0.4) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->widis-lstm-tools==0.4) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->widis-lstm-tools==0.4) (1.15.0)\n",
            "Building wheels for collected packages: widis-lstm-tools\n",
            "  Building wheel for widis-lstm-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for widis-lstm-tools: filename=widis_lstm_tools-0.4-cp36-none-any.whl size=43228 sha256=db59e85d2bcc5574936d1aac7158b9c089466c974c243c34e2eb2b4f0f391258\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qr7s2zzq/wheels/a4/f3/2b/9a49ec2d9387e8c376e6ba7e02323b2657ba1980a483535a72\n",
            "Successfully built widis-lstm-tools\n",
            "Installing collected packages: widis-lstm-tools\n",
            "Successfully installed widis-lstm-tools-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26mkTjZlwGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "844e145d-99ce-43bd-870b-543520dccf1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLYECgrMkFcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "478dca5a-402c-4dda-dc19-830f382a7324"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/fullsequence.pkl', 'rb') as f:\n",
        "    fulldata = pickle.load(f)\n",
        "full_sequences = fulldata\n",
        "with open('/content/drive/My Drive/Colab Notebooks/uni2go.pkl', 'rb') as f:\n",
        "    # Pickle will store our object into the specified file\n",
        "    uni_data = pickle.load(f)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/goid.pkl', 'rb') as f:\n",
        "    # Pickle will store our object into the specified file\n",
        "    ggid = pickle.load(f)\n",
        "gid = h5py.File('/content/drive/My Drive/Colab Notebooks/one_hot_go.h5py','r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d360600e6960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/fullsequence.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfulldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfull_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfulldata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/uni2go.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Pickle will store our object into the specified file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Bio/Alphabet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m raise ImportError(\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;34m\"Bio.Alphabet has been removed from Biopython. In many cases, the alphabet can simply be ignored and removed from scripts. In a few cases, you may need to specify the ``molecule_type`` as an annotation on a SeqRecord for your script to work correctly. Please see https://biopython.org/wiki/Alphabet for more information.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
            "\u001b[0;31mImportError\u001b[0m: Bio.Alphabet has been removed from Biopython. In many cases, the alphabet can simply be ignored and removed from scripts. In a few cases, you may need to specify the ``molecule_type`` as an annotation on a SeqRecord for your script to work correctly. Please see https://biopython.org/wiki/Alphabet for more information.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigJ05FPhg1M",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKpaJi5bOZmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "print(len(full_sequences))\n",
        "b1 = len(full_sequences)*.01\n",
        "b2 = len(full_sequences)*.99\n",
        "print(b1,b2)\n",
        "counts = []\n",
        "e = []\n",
        "classes =[]\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "for value in ggid.values():\n",
        "  if value>250:\n",
        "    e.append(value)\n",
        "print('mean:'+str(sum(e)/len(e)))\n",
        "print('classes left from 30821 which have sequences connected to them :'+str(len(e)))\n",
        "i = 0\n",
        "for v in e:\n",
        "  if v<=(sum(e)/len(e)):\n",
        "    i+=1\n",
        "print('classes under the mean or equal:'+str(i))\n",
        "import matplotlib.pyplot as plt\n",
        "for key in ggid.keys():\n",
        "  if 600>ggid[key]>200:\n",
        "    classes.append(key)\n",
        "    counts.append(ggid[key])\n",
        "print(len(classes))\n",
        "print(len(counts))\n",
        "from matplotlib import pyplot as plt\n",
        "k = zip(classes,counts)\n",
        "newggid = dict(k)\n",
        "with open('newgoid.pkl', 'wb') as f:\n",
        "    pickle.dump(newggid, f)\n",
        "    print('done')\n",
        "print(len(newggid.keys()))\n",
        "print(set(classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGVAZf00QThb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "print(counts)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(counts)\n",
        "plt.title(\"Annotations in each goid\",fontsize=20)\n",
        "plt.xticks(fontsize= 10)\n",
        "plt.yticks(fontsize= 10)\n",
        "plt.xlabel('GO-ID',fontsize=20)\n",
        "plt.ylabel('Occurences',fontsize=20)\n",
        "plt.show()\n",
        "plt.savefig('data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-SE6UhrQVu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XMVf_zBKgh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "top_10_idx = np.argsort(list(ggid.values()))[-10:]\n",
        "top_10_values = [list(ggid.values())[i] for i in top_10_idx]\n",
        "top_10_keys = [list(ggid.keys())[i] for i in top_10_idx]\n",
        "\n",
        "print('top ten classes which have the most sequences=',top_10_keys)\n",
        "top_10_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLjzUkC0_jSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjpMVHzN_jxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datadict={}\n",
        "for key in fulldata.keys():\n",
        "  datadict[fulldata[key]] = list(uni_data[key])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpddCGt1-ZZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binarizerlist = []\n",
        "for key in newggid.keys():\n",
        "  g = []\n",
        "  for values in datadict.values():\n",
        "    if key in values:\n",
        "      g.append(1)\n",
        "    else:\n",
        "      g.append(0)\n",
        "  binarizerlist.append(g)\n",
        "len(binarizerlist)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6_Xv2cPwa1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "vocab = 'MAFSEDVLKYRPNWQCGIHTXZBUO'\n",
        "aa_lookup = dict([(k, v) for v, k in enumerate(vocab)])\n",
        "bin_seq = []\n",
        "for sequence in datadict.keys():  \n",
        "  x = np.zeros(shape=(len(sequence), len(aa_lookup)), dtype=np.float32)\n",
        "  x[np.arange(len(sequence)), [aa_lookup[aa] for aa in sequence]] = 1\n",
        "  print(len(x))\n",
        "  bin_seq.append(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1aJXjG1DlDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columnst = {}\n",
        "columnst['sequences'] = bin_seq\n",
        "for key in newggid.keys():\n",
        "  columnst[str('GO:'+str(key))] = binarizerlist[list(newggid.keys()).index(key)]\n",
        "columnst.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI1lYz6-BFm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdms\n",
        "# Assign data to tuples.  \n",
        "  \n",
        "  \n",
        "# Converting lists of tuples into  \n",
        "# pandas Dataframe.  \n",
        "df = pd.DataFrame(columnst)  \n",
        "     \n",
        "# Print data.\n",
        "df\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIOmRPtnPMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = list(df.columns.values)[1:]\n",
        "sns.set(font_scale = .05)\n",
        "plt.figure()\n",
        "\n",
        "print('1')\n",
        "ax= sns.barplot(categories, df.iloc[:].sum().values)\n",
        "plt.title(\"Annotations in each goid\", fontsize=24)\n",
        "plt.ylabel('Number of Annotations', fontsize=18)\n",
        "plt.xlabel('GoID', fontsize=18)\n",
        "#adding the text labels\n",
        "print('2')\n",
        "rects = ax.patches\n",
        "labels = df.iloc[:].sum().values\n",
        "print('3')\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=8)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqCgkbRrqX4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newdf = df[df.iloc[:,1:].sum(axis=1)>0]\n",
        "newdf\n",
        "rowSums = newdf.iloc[1:,:].sum(axis=1)\n",
        "multiLabel_counts = rowSums.value_counts()\n",
        "multiLabel_counts = multiLabel_counts.iloc[:]\n",
        "print(multiLabel_counts.values)\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n",
        "plt.title(\"sequences having multiple labels \")\n",
        "plt.ylabel('Number of sequences', fontsize=18)\n",
        "plt.xlabel('Number of labels', fontsize=18)\n",
        "#adding the text labels\n",
        "rects = ax.patches\n",
        "labels = multiLabel_counts.values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnWutFQe4xew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiLabel_counts.values\n",
        "rowSums.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlXjiiYVt8vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(classes,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZNlxP11L25s",
        "colab_type": "text"
      },
      "source": [
        "#Classifier Chain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XylcedmZL-D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from  sklearn.metrics import balanced_accuracy_score,auc,f1_score,roc_curve\n",
        "from  sklearn.ensemble import RandomForestClassifier \n",
        "\n",
        "X = df['sequences']\n",
        "Y = df.drop('sequences',axis=1)\n",
        "x_train, x_test,y_train,y_test =train_test_split(X, Y, test_size=0.2, random_state=42) \n",
        "newlist = []\n",
        "auclist = []\n",
        "bacclist = []\n",
        "f1_list = []\n",
        "for i in Y.keys():\n",
        "    task = str(i)\n",
        "    y_train = y_train[task]\n",
        "    x_trains = x_train\n",
        "    print(y_train,x_trains)\n",
        "    RN = RandomForestClassifier(random_state = 3,n_jobs=60, n_estimators=200)\n",
        "    RN.fit(x_trains,y_train)\n",
        "    v = RN.predict(y_test)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test[i], v)\n",
        "    aucs = auc(fpr, tpr)\n",
        "    baccur = balanced_accuracy_score(y_test,v)\n",
        "    f1 = f1_score(y_test,v)\n",
        "    auclist.append(aucs)\n",
        "    newlist.append(RN)\n",
        "    bacclist.append(baccur)\n",
        "    f1_list.append(f1)\n",
        "print(len(auclist),len(newlist))#check if the list are the same size, for the next step \n",
        "print(auclist)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXFSphhhL-Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyhqEq2LL-d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM_hxieEMAdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFCf-HJhtEtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(classes)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JSzIj_PYmI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = []\n",
        "labels = []\n",
        "go_matrix = gid['one_hot_dag'][:]\n",
        "goid_to_index = gid['go_id_to_index'][:]\n",
        "allowed_goids = np.array(list(ggid.values()))>-1\n",
        "label = np.zeros_like(go_matrix[0], dtype=np.float32).flatten()\n",
        "for key in datadict.keys():\n",
        "  for go_id in datadict[key]:\n",
        "    goid_to_idx = goid_to_index[go_id]\n",
        "    if goid_to_idx >= 0:\n",
        "      label += go_matrix[goid_to_idx]\n",
        "    label[:] = label > 0\n",
        "    label = label[allowed_goids]\n",
        "    classes.append(label)\n",
        "  \n",
        "print(len(classes))\n",
        "print(len(sequences))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDHOvahd_kMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = []\n",
        "sequences = []\n",
        "for key in datadict.keys():\n",
        "  classes= classes+datadict[key]\n",
        "  sequences.extend([key]*len(datadict[key]))\n",
        "  \n",
        "print(len(classes))\n",
        "print(len(sequences))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrb1pzWFe2BU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXlUeQhBmmJl",
        "colab_type": "text"
      },
      "source": [
        "chose the samples which only have one label to make it easier then choose the multilabel ones later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekL8ZEGNe4Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6azkkloHX26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_tags = df.groupby(\"GOID\", sort='count').size().reset_index(name='count')\n",
        "fig = plt.figure()\n",
        "grouped_tags.plot(title=\"Tag frequency\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESU9-Ezav2tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fulldataset = pd.DataFrame(bin_seq,classes,columns = ['Sequence','Connected classes'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS_BH3cFlEuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = fulldataset['Connected classes']\n",
        "X = fulldataset['Sequence'] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS-4YubrHIrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DummyClassifier to predict only target 0\n",
        "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
        "dummy_pred = dummy.predict(X_test)\n",
        "print(dummy_pred)\n",
        "# checking unique labels\n",
        "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
        "\n",
        "# checking accuracy\n",
        "print('Test score: ', accuracy_score(y_test, dummy_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSNyfTcpmZeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "labels = []\n",
        "go_matrix = gid['one_hot_dag'][:]\n",
        "goid_to_index = gid['go_id_to_index'][:]\n",
        "allowed_goids = np.array(list(ggid.values()))>-1\n",
        "label = np.zeros_like(go_matrix[0], dtype=np.float32).flatten()\n",
        "for go_id in classes:\n",
        "  goid_to_idx = goid_to_index[go_id]\n",
        "  if goid_to_idx >= 0:\n",
        "    label += go_matrix[goid_to_idx]\n",
        "  label[:] = label > 0\n",
        "  label = label[allowed_goids]\n",
        "  labels.append(label)\n",
        "  import numpy as np\n",
        "\n",
        "classes = []\n",
        "labels = []\n",
        "go_matrix = gid['one_hot_dag'][:]\n",
        "goid_to_index = gid['go_id_to_index'][:]\n",
        "allowed_goids = np.array(list(ggid.values()))>-1\n",
        "label = np.zeros_like(go_matrix[0], dtype=np.float32).flatten()\n",
        "for key in datadict.keys():\n",
        "  for go_id in datadict[key]:\n",
        "    goid_to_idx = goid_to_index[go_id]\n",
        "    if goid_to_idx >= 0:\n",
        "      label += go_matrix[goid_to_idx]\n",
        "    label[:] = label > 0\n",
        "    label = label[allowed_goids]\n",
        "    classes.append(label)\n",
        "  \n",
        "print(len(classes))\n",
        "print(len(sequences))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}